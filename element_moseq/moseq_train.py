"""
Code adapted from the Datta Lab: https://dattalab.github.io/moseq2-website/index.html
DataJoint Schema for Keypoint-MoSeq training pipeline
"""

import importlib
import inspect
import os
import pickle
from datetime import datetime, timezone
from pathlib import Path
from typing import Optional

import cv2
import datajoint as dj
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import yaml
from element_interface.utils import find_full_path

# Configure JAX for better compatibility with DataJoint/DeepHash
os.environ["JAX_ENABLE_X64"] = "False"
os.environ["JAX_ARRAY"] = "False"  # Use legacy array API for better compatibility
os.environ["JAX_DYNAMIC_SHAPES"] = "False"

from .plotting import viz_utils
from .readers import kpms_reader

schema = dj.schema()
_linking_module = None
logger = dj.logger


def activate(
    train_schema_name: str,
    *,
    create_schema: bool = True,
    create_tables: bool = True,
    linking_module: str = None,
):
    """Activate this schema.

    Args:
        train_schema_name (str): A string containing the name of the `moseq_train` schema.
        create_schema (bool): If True (default), schema will be created in the database.
        create_tables (bool): If True (default), tables related to the schema will be created in the database.
        linking_module (str): A string containing the module name or module containing the required dependencies to activate the schema.
    Functions:
        get_kpms_root_data_dir(): Returns absolute path for root data directory/ies
                                  with all behavioral recordings, as (list of) string(s).
        get_kpms_processed_data_dir(): Optional. Returns absolute path for processed
                                       data.
    """

    if isinstance(linking_module, str):
        linking_module = importlib.import_module(linking_module)
    assert inspect.ismodule(
        linking_module
    ), "The argument 'dependency' must be a module's name or a module object"

    assert hasattr(
        linking_module, "get_kpms_root_data_dir"
    ), "The linking module must specify a lookup function for a root data directory"

    global _linking_module
    _linking_module = linking_module

    # activate
    schema.activate(
        train_schema_name,
        create_schema=create_schema,
        create_tables=create_tables,
        add_objects=_linking_module.__dict__,
    )


# -------------- Functions required by element-moseq ---------------


def get_kpms_root_data_dir() -> list:
    """Fetches absolute data path to kpms data directories.

    The absolute path here is used as a reference for all downstream relative paths used in DataJoint.

    Returns:
        A list of the absolute path(s) to kpms data directories.
    """

    root_directories = _linking_module.get_kpms_root_data_dir()
    if isinstance(root_directories, (str, Path)):
        root_directories = [root_directories]

    if (
        hasattr(_linking_module, "get_kpms_processed_data_dir")
        and get_kpms_processed_data_dir() not in root_directories
    ):
        root_directories.append(_linking_module.get_kpms_processed_data_dir())

    return root_directories


def get_kpms_processed_data_dir() -> Optional[str]:
    """Retrieve the root directory for all processed data.

    Returns:
        A string for the full path to the root directory for processed data.
    """
    if hasattr(_linking_module, "get_kpms_processed_data_dir"):
        return _linking_module.get_kpms_processed_data_dir()
    else:
        return None


# ----------------------------- Table declarations ----------------------


@schema
class PoseEstimationMethod(dj.Lookup):
    """Name of the pose estimation method supported by the keypoint loader of `keypoint-moseq` package.

    Attributes:
        pose_estimation_method  (str): Supported pose estimation method (deeplabcut, sleap, anipose, sleap-anipose, nwb, facemap)
        pose_estimation_desc    (str): Optional. Pose estimation method description with the supported formats.
    """

    definition = """
    # Pose estimation methods supported by the keypoint loader of `keypoint-moseq` package.
    pose_estimation_method  : char(15)         # Supported pose estimation method (deeplabcut, sleap, anipose, sleap-anipose, nwb, facemap)
    ---
    pose_estimation_desc    : varchar(1000)    # Optional. Pose estimation method description with the supported formats.
    """

    contents = [
        ["deeplabcut", "`.csv` and `.h5/.hdf5` files generated by DeepLabcut analysis"],
        ["sleap", "`.slp` and `.h5/.hdf5` files generated by SLEAP analysis"],
        ["anipose", "`.csv` files generated by anipose analysis"],
        ["sleap-anipose", "`.h5/.hdf5` files generated by sleap-anipose analysis"],
        ["nwb", "`.nwb` files with Neurodata Without Borders (NWB) format"],
        ["facemap", "`.h5` files generated by Facemap analysis"],
    ]


@schema
class KeypointSet(dj.Manual):
    """Store the keypoint data and the video set directory for model training.

    Attributes:
        kpset_id (int)                          : Unique ID for each keypoint set.
        PoseEstimationMethod (foreign key)      : Unique format method used to obtain the keypoints data.
        kpset_dir (str)                         : Path where the keypoint files are located together with the pose estimation `config` file, relative to root data directory.
        kpset_desc (str)                        : Optional. User-entered description.
    """

    definition = """
    kpset_id                        : int           # Unique ID for each keypoint set
    ---
    -> PoseEstimationMethod                         # Unique format method used to obtain the keypoints data
    kpset_dir                       : varchar(255)  # Path where the keypoint files are located together with the pose estimation `config` file, relative to root data directory
    kpset_desc=''                   : varchar(1000) # Optional. User-entered description
    """

    class VideoFile(dj.Part):
        """Store the IDs and file paths of each video file that will be used for model training.

        Attributes:
            KeypointSet (foreign key) : Unique ID for each keypoint set.
            video_id (int)            : Unique ID for each video corresponding to each keypoint data file, relative to root data directory.
            video_path (str)          : Filepath of each video from which the keypoints are derived, relative to root data directory.
        """

        definition = """
        -> master
        video_id                            : int           # Unique ID for each video corresponding to each keypoint data file, relative to root data directory
        ---
        video_path                          : varchar(1000) # Filepath of each video (e.g., `.mp4`) from which the keypoints are derived, relative to root data directory
        pose_estimation_path=''             : varchar(1000) # Filepath of each pose estimation file (e.g., `.h5`) that contains the keypoints, relative to root data directory
        """


@schema
class BodyParts(dj.Manual):
    """Store the body parts to use in the analysis.

    Attributes:
        KeypointSet (foreign key)       : Unique ID for each `KeypointSet` key.
        bodyparts_id (int)              : Unique ID for a set of bodyparts for a particular keypoint set.
        anterior_bodyparts (blob)       : List of strings of anterior bodyparts
        posterior_bodyparts (blob)      : List of strings of posterior bodyparts
        use_bodyparts (blob)            : List of strings of bodyparts to be used
        bodyparts_desc (varchar)        : Optional. User-entered description.
    """

    definition = """
    -> KeypointSet                              # Unique ID for each `KeypointSet` key
    bodyparts_id                : int           # Unique ID for a set of bodyparts for a particular keypoint set
    ---
    anterior_bodyparts          : blob          # List of strings of anterior bodyparts
    posterior_bodyparts         : blob          # List of strings of posterior bodyparts
    use_bodyparts               : blob          # List of strings of bodyparts to be used
    bodyparts_desc=''           : varchar(1000) # Optional. User-entered description
    """


@schema
class PCATask(dj.Manual):
    """
    Define the Principal Component Analysis (PCA) task for dimensionality reduction of keypoint data.

    Attributes:
        BodyParts (foreign key)         : Unique ID for each `BodyParts` key
        outlier_scale_factor (float)    : Scale factor for outlier detection in keypoint data (default: 6)
        kpms_project_output_dir (str)   : Optional. Keypoint-MoSeq project output directory, relative to root data directory
        task_mode (enum)                : 'load' to load existing results, 'trigger' to compute new PCA
    """

    definition = """
    -> BodyParts                                            # Unique ID for each `BodyParts` key
    ---
    outlier_scale_factor=6          : float                 # Scale factor for outlier detection in keypoint data (default: 6)
    kpms_project_output_dir=''      : varchar(255)          # Optional. Keypoint-MoSeq project output directory, relative to root data directory
    task_mode='load'                :enum('load','trigger') # 'load' to load existing results, 'trigger' to compute new PCA
    """

    @classmethod
    def infer_output_dir(cls, key: dict, relative: bool = False, mkdir: bool = False):
        """Return the expected kpms_project_output_dir.

        If kpms_project_output_dir is empty, generates a default based on keypointset and session info.

        Args:
            key: DataJoint key specifying a PCATask.
            relative (bool): Report directory relative to processed data directory.
            mkdir (bool): Default False. Make directory if it doesn't exist.
        """
        # Get keypointset info for default naming
        kpset_id = (KeypointSet & key).fetch1("kpset_id")

        # Get bodyparts info for unique naming
        bodyparts_id = (BodyParts & key).fetch1("bodyparts_id")

        # Generate default output directory name
        default_output_dir = f"kpset_id_{kpset_id}_bodyparts_id_{bodyparts_id}"

        if mkdir:
            # Create directory in the processed directory
            output_dir = Path(get_kpms_processed_data_dir()) / default_output_dir
            output_dir.mkdir(parents=True, exist_ok=True)

        return default_output_dir


@schema
class PreProcessing(dj.Computed):
    """
    Preprocess keypoint data by cleaning outliers and setting up the Keypoint-MoSeq project configuration.

    Attributes:
        PCATask (foreign key)           : Unique ID for each `PCATask` key.
        coordinates (longblob)          : Cleaned coordinates dictionary after outlier removal.
        confidences (longblob)          : Cleaned confidences dictionary after outlier removal.
        average_frame_rate (int)        : Average frame rate of the videos for model training (used for kappa calculation).
        pre_processing_time (datetime)  : datetime of the preprocessing execution.
        pre_processing_duration (int)   : Execution time of the preprocessing in seconds.
    """

    definition = """
    -> PCATask                                  # Unique ID for each `PCATask` key
    ---
    coordinates                     : longblob  # Cleaned coordinates dictionary after outlier removal.
    confidences                     : longblob  # Cleaned confidences dictionary after outlier removal.
    average_frame_rate              : int       # Average frame rate of the videos for model training (used for kappa calculation).
    pre_processing_time=NULL        : datetime  # datetime of the preprocessing execution.
    pre_processing_duration=NULL    : int       # Execution time of the preprocessing in seconds.
    """

    class Video(dj.Part):
        definition = """
        -> master
        video_id: varchar(255)
        ---
        video_duration              : int           # Duration of each video in minutes
        frame_rate                  : float         # Frame rate of the video in frames per second (Hz)
        file_size                   : float         # File size of the video in megabytes (MB)
        """

    class ConfigFile(dj.Part):
        """
        Store the configuration files (first creation of the config file and the updates after processing).
        """

        definition = """
        -> master
        ---
        base_config_file=NULL : attach       # Base KPMS config attachment.
        config_file           : attach       # Updated KPMS DJ config attachment.
        """

    def make_fetch(self, key):
        """
        Fetch required data for preprocessing from database tables.
        """
        anterior_bodyparts, posterior_bodyparts, use_bodyparts = (
            BodyParts & key
        ).fetch1(
            "anterior_bodyparts",
            "posterior_bodyparts",
            "use_bodyparts",
        )
        pose_estimation_method, kpset_dir = (KeypointSet & key).fetch1(
            "pose_estimation_method", "kpset_dir"
        )
        keypoint_videofile_metadata = (KeypointSet.VideoFile & key).fetch(as_dict=True)
        kpms_project_output_dir, task_mode, outlier_scale_factor = (
            PCATask & key
        ).fetch1("kpms_project_output_dir", "task_mode", "outlier_scale_factor")

        return (
            anterior_bodyparts,
            posterior_bodyparts,
            use_bodyparts,
            pose_estimation_method,
            kpset_dir,
            keypoint_videofile_metadata,
            kpms_project_output_dir,
            task_mode,
            outlier_scale_factor,
        )

    def make_compute(
        self,
        key,
        anterior_bodyparts,
        posterior_bodyparts,
        use_bodyparts,
        pose_estimation_method,
        kpset_dir,
        keypoint_videofile_metadata,
        kpms_project_output_dir,
        task_mode,
        outlier_scale_factor,
    ):
        """
        Compute preprocessing steps including outlier removal and video metadata extraction.

        Args:
            key (dict): Primary key from the `PCATask` table.
            anterior_bodyparts (list): List of anterior bodyparts.
            posterior_bodyparts (list): List of posterior bodyparts.
            use_bodyparts (list): List of bodyparts to use.
            pose_estimation_method (str): Pose estimation method (e.g., 'deeplabcut').
            kpset_dir (str): Keypoint set directory path.
            video_paths (list): List of video file paths.
            video_ids (list): List of video IDs.
            kpms_project_output_dir (str): Project output directory path.
            task_mode (str): Task mode ('load' or 'trigger').
            outlier_scale_factor (int): Scale factor for outlier detection.

        Returns:
            tuple: Processed data including cleaned coordinates, confidences, and video metadata.

        Raises:
            NotImplementedError: Only `deeplabcut` pose estimation method is supported.
            FileNotFoundError: No DLC config file found in `kpset_dir`.

        High-Level Logic:
        1. Find the first existing pose estimation config file in the `kpset_dir` directory, if not found, raise an error.
        2. Check that the pose_estimation_method is `deeplabcut` and set up the project output directory with the default `config.yml`.
        3. Create the `kpms_project_output_dir` (if it does not exist), and generates the kpms default `config.yml` with the default values from the pose estimation config.
        4. Create a copy of the kpms `config.yml` named `kpms_dj_config.yml` that will be updated with both the `video_dir` and bodyparts
        5. Load keypoint data from the keypoint files found in the `kpset_dir` that will serve as the training set.
        6. Detect and remove outlier keypoints using medoid distance analysis, then interpolate missing values.
        7. Calculate the average frame rate and the frame rate list of the videoset from which the keypoint set is derived. These two attributes can be used to calculate the kappa value.
        """
        import jax
        from keypoint_moseq import (
            find_medoid_distance_outliers,
            interpolate_keypoints,
            load_keypoints,
            outlier_removal,
            overlay_keypoints_on_video,
        )

        from .plotting.viz_utils import plot_medoid_distance_outliers

        jax.config.update("jax_enable_x64", True)

        execution_time = datetime.now(timezone.utc)

        if task_mode == "trigger":
            from keypoint_moseq import setup_project

            # Resolve kpms_project_output_dir to absolute and create it if needed
            if not kpms_project_output_dir:
                kpms_project_output_dir = PCATask.infer_output_dir(
                    key, relative=True, mkdir=True
                )
                PCATask.update1(
                    {**key, "kpms_project_output_dir": kpms_project_output_dir}
                )
            kpms_project_output_dir = (
                Path(get_kpms_processed_data_dir()) / kpms_project_output_dir
            )

            # Resolve kpset_dir to absolute and check if it exists
            kpset_dir = find_full_path(get_kpms_root_data_dir(), kpset_dir)
            if not kpset_dir.exists():
                raise FileNotFoundError(
                    f"No keypoint set directory found in {kpset_dir}"
                )

            # Find the pose estimation config file
            pose_estimation_config_file = Path(
                kpms_reader._pose_estimation_config_path(kpset_dir)
            )
            if not pose_estimation_config_file.exists():
                raise FileNotFoundError(
                    f"No config file (`config.yml` or `config.yaml`) found in {kpset_dir}"
                )

            if pose_estimation_method == "deeplabcut":
                setup_project(
                    project_dir=kpms_project_output_dir.as_posix(),
                    deeplabcut_config=pose_estimation_config_file.as_posix(),
                    overwrite=True,  # Allow regenerating config if directory exists
                )
            else:
                raise NotImplementedError(
                    "Currently, `deeplabcut` is the only pose estimation method supported by this Element. Please reach out at `support@datajoint.com` if you use another method."
                )
        # task mode is load
        else:
            kpms_project_output_dir = find_full_path(
                get_kpms_processed_data_dir(), kpms_project_output_dir
            )
            kpset_dir = find_full_path(get_kpms_root_data_dir(), kpset_dir)

        # Format keypoint data
        raw_coordinates, raw_confidences, formatted_bodyparts = load_keypoints(
            filepath_pattern=kpset_dir, format=pose_estimation_method
        )

        # Confirm that `use_bodyparts` are a subset of `formatted_bodyparts`
        if not set(use_bodyparts).issubset(set(formatted_bodyparts)):
            raise ValueError(
                f"use_bodyparts ({use_bodyparts}) is not a subset of formatted bodyparts ({formatted_bodyparts})"
            )

        # Use only the bodyparts in `use_bodyparts`
        use_bodypart_indices = [formatted_bodyparts.index(bp) for bp in use_bodyparts]
        filtered_coordinates = {}
        filtered_confidences = {}
        for recording_name in raw_coordinates:
            filtered_coordinates[recording_name] = raw_coordinates[recording_name][
                :, use_bodypart_indices, :
            ]
            filtered_confidences[recording_name] = raw_confidences[recording_name][
                :, use_bodypart_indices
            ]

        # Sanity check of the number of features (dimensions) in the filtered_coordinates
        num_bodyparts = len(use_bodyparts)
        num_features = num_bodyparts * 2  # (x, y) coordinates for each bodypart
        for recording_name in filtered_coordinates:
            coords_shape = filtered_coordinates[
                recording_name
            ].shape  # Typically (frames, bodyparts, 2)
            actual_features = (
                coords_shape[1] * coords_shape[2]
            )  # bodyparts * 2 (for x/y)
            if actual_features != num_features:
                raise ValueError(
                    f"Feature mismatch in {recording_name}: "
                    f"expected {num_features}, got {actual_features}"
                )

        # Get frame rates and file sizes for each video
        video_metadata_dict = dict()
        frame_rates = []
        for row in keypoint_videofile_metadata:
            video_id = int(row["video_id"])
            video_path = find_full_path(get_kpms_root_data_dir(), row["video_path"])

            # Get file size in MB (rounded to 2 decimal places)
            file_size_mb = round(video_path.stat().st_size / (1024 * 1024), 2)

            # Get video properties
            cap = cv2.VideoCapture(video_path.as_posix())
            fps = float(cap.get(cv2.CAP_PROP_FPS))
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            cap.release()
            if fps <= 0:
                raise ValueError(
                    f"Invalid FPS ({fps}) for video_id {video_id} at {video_path}"
                )
            duration_minutes = int((frame_count / fps) / 60.0)
            frame_rates.append(fps)
            video_metadata_dict[video_id] = {
                "video_duration": duration_minutes,
                "frame_rate": fps,
                "file_size": file_size_mb,
                "outlier_plot": None,
            }
        average_frame_rate = int(round(np.mean(frame_rates)))

        # Get all unique parent directories for all video files
        parent_dirs = {
            Path(video["video_path"]).parent for video in keypoint_videofile_metadata
        }
        # Check if there is only one unique parent
        if len(parent_dirs) > 1:
            raise ValueError(
                f"Videos are located in multiple directories: {parent_dirs}. All videos must be in the same directory."
            )
        videos_dir = find_full_path(
            get_kpms_root_data_dir(),
            Path(keypoint_videofile_metadata[0]["video_path"]).parent,
        )

        # Filter anterior/posterior to only include those present in use_bodyparts
        filtered_anterior = [bp for bp in anterior_bodyparts if bp in use_bodyparts]
        filtered_posterior = [bp for bp in posterior_bodyparts if bp in use_bodyparts]

        # Sanity check: Ensure all filtered anterior/posterior bodyparts are in use_bodyparts
        if not set(filtered_anterior).issubset(set(use_bodyparts)):
            raise ValueError(
                f"Filtered anterior bodyparts contain elements not in use_bodyparts: {set(filtered_anterior) - set(use_bodyparts)}"
            )
        if not set(filtered_posterior).issubset(set(use_bodyparts)):
            raise ValueError(
                f"Filtered posterior bodyparts contain elements not in use_bodyparts: {set(filtered_posterior) - set(use_bodyparts)}"
            )

        # Generate KPMS DJ config file with all new parameters
        (
            kpms_dj_config_path,
            kpms_dj_config_dict,
            kpms_base_config_path,
            kpms_base_config_dict,
        ) = kpms_reader.dj_generate_config(
            kpms_project_dir=kpms_project_output_dir,
            video_dir=str(videos_dir),
            use_bodyparts=list(use_bodyparts),
            anterior_bodyparts=filtered_anterior,
            posterior_bodyparts=filtered_posterior,
            outlier_scale_factor=float(outlier_scale_factor),
            fps=average_frame_rate,  # Pass fps directly to avoid redundant update
        )

        # Get absolute paths for attach fields
        kpms_dj_config_path = find_full_path(
            get_kpms_processed_data_dir(), kpms_dj_config_path
        )
        kpms_base_config_path = find_full_path(
            get_kpms_processed_data_dir(), kpms_base_config_path
        )

        logger.info("Starting outlier removal...")

        # Apply outlier removal to all recordings at once
        cleaned_coordinates, cleaned_confidences = outlier_removal(
            coordinates=filtered_coordinates,
            confidences=filtered_confidences,
            project_dir=kpms_project_output_dir.as_posix(),
            overwrite=False,
            outlier_scale_factor=outlier_scale_factor,
            bodyparts=list(use_bodyparts),
        )
        logger.info("...Outlier removal completed")

        completion_time = datetime.now(timezone.utc)
        duration_seconds = (
            (completion_time - execution_time).total_seconds()
            if task_mode == "trigger"
            else None
        )

        return (
            cleaned_coordinates,
            cleaned_confidences,
            average_frame_rate,
            video_metadata_dict,
            kpms_dj_config_path,
            kpms_base_config_path,
            execution_time,
            duration_seconds,
        )

    def make_insert(
        self,
        key,
        cleaned_coordinates,
        cleaned_confidences,
        average_frame_rate,
        video_metadata_dict,
        kpms_dj_config_path,
        kpms_base_config_path,
        execution_time,
        duration_seconds,
    ):
        """
        Insert processed data into the PreProcessing table and part tables.
        """

        # Insert in the main table
        self.insert1(
            {
                **key,
                "coordinates": cleaned_coordinates,
                "confidences": cleaned_confidences,
                "average_frame_rate": average_frame_rate,
                "pre_processing_time": execution_time,
                "pre_processing_duration": duration_seconds,
            }
        )

        # Insert video metadata in Video table
        if video_metadata_dict:
            self.Video.insert(
                [
                    {
                        **key,
                        "video_id": vid,
                        "video_duration": meta["video_duration"],
                        "frame_rate": meta["frame_rate"],
                        "file_size": meta["file_size"],
                    }
                    for vid, meta in video_metadata_dict.items()
                ]
            )

        # Insert configuration files
        self.ConfigFile.insert1(
            {
                **key,
                "config_file": kpms_dj_config_path,
                "base_config_file": kpms_base_config_path,
            }
        )


@schema
class PreProcessingQA(dj.Computed):
    """
    Check if any bodyparts have a high proportion of NaNs and generate and store QA materials (outlier removal plots and overlay videos).
    Attributes:
        PreProcessing (foreign key)     : `PreProcessing` Key.
        nan_df (longblob)                : DataFrame containing NaN proportion breakdown by bodypart.
    """

    definition = """
    -> PreProcessing                      # `PreProcessing` Key
    ---
    nan_breakdown             : attach  # HTML table containing NaN proportion breakdown by bodypart
    qa_duration               : float   # Duration of QA in seconds
    """

    class VideoQA(dj.Part):
        """Store QA materials: outlier plots and overlay videos."""

        definition = """
        -> master
        video_id    : varchar(255)
        ---
        outlier_plot       : attach # QA visualization showing detected outliers and interpolation.
        overlay_video      : attach  # Overlay keypoints on the video attachment.
        """

    def make_fetch(self, key):
        """
        Fetch required data for QA processing from database tables.
        """
        use_bodyparts = (BodyParts & key).fetch1("use_bodyparts")
        coordinates = (PreProcessing & key).fetch1("coordinates")
        kpms_project_output_dir = (PCATask & key).fetch1("kpms_project_output_dir")
        kpms_project_output_dir = find_full_path(
            get_kpms_processed_data_dir(), kpms_project_output_dir
        )
        kpms_dj_config_path = (PreProcessing.ConfigFile & key).fetch1("config_file")
        keypoint_videofile_metadata = (KeypointSet.VideoFile & key).fetch(as_dict=True)
        fps_lookup = (PreProcessing.Video & key).fetch(
            "video_id", "frame_rate", as_dict=True
        )
        return (
            use_bodyparts,
            coordinates,
            kpms_project_output_dir,
            kpms_dj_config_path,
            keypoint_videofile_metadata,
            fps_lookup,
        )

    def make_compute(
        self,
        key,
        use_bodyparts,
        coordinates,
        kpms_project_output_dir,
        kpms_dj_config_path,
        keypoint_videofile_metadata,
        fps_lookup,
    ):
        """
        Compute QA materials including NaN analysis and overlay video generation.

        Args:
            key (dict): Primary key from the `PreProcessing` table.
            coordinates (dict): Cleaned coordinates dictionary.
            kpms_project_output_dir (Path): Project output directory path.
            kpms_dj_config_dict (dict): KPMS configuration dictionary.
            keypoint_videofile_metadata (list): Video metadata list.

        Returns:
            tuple: QA data including breakdown data, QA materials, and duration.
        """
        from keypoint_moseq import overlay_keypoints_on_video

        fps_lookup = {v["video_id"]: float(v["frame_rate"]) for v in fps_lookup}

        kpms_dj_config_path = (PreProcessing.ConfigFile & key).fetch1("config_file")
        kpms_dj_config_dict = kpms_reader.load_kpms_dj_config(
            config_path=kpms_dj_config_path,
            build_indexes=True,
        )

        execution_time = datetime.now(timezone.utc)

        # Calculate NaN proportions breakdown for each recording and bodypart
        # Replicating keypoint-moseq's check_nan_proportions logic
        keys = sorted(coordinates.keys())
        nan_props = [np.isnan(coordinates[k]).any(-1).mean(0) for k in keys]

        # Create the DataFrame for HTML table
        nan_df = pd.DataFrame(data=nan_props, index=keys, columns=use_bodyparts)
        nan_styler = (
            nan_df.style.background_gradient(cmap="RdYlBu_r", axis=None)
            .format("{:.1%}")
            .set_caption(
                '<h2 style="color:#333;text-align:center;">NaN Proportion Breakdown</h2>'
            )
            .set_table_styles(
                [
                    {
                        "selector": "th",
                        "props": [
                            ("font-size", "11pt"),
                            ("background-color", "#F2F2F2"),
                            ("color", "#222"),
                            ("font-weight", "bold"),
                            ("padding", "8px"),
                        ],
                    },
                    {
                        "selector": "td",
                        "props": [
                            ("font-size", "10pt"),
                            ("padding", "6px 12px"),
                            ("text-align", "center"),
                        ],
                    },
                    {
                        "selector": "caption",
                        "props": [
                            ("caption-side", "top"),
                            ("font-size", "14pt"),
                            ("color", "#29487d"),
                            ("font-weight", "bold"),
                            ("margin-bottom", "12px"),
                        ],
                    },
                    {
                        "selector": "",
                        "props": [
                            ("border-collapse", "collapse"),
                            ("margin", "25px auto"),
                        ],
                    },
                ]
            )
            .set_properties(**{"border": "1px solid #ddd"})
        )

        # Save HTML to temporary file for DataJoint attach
        import tempfile

        with tempfile.NamedTemporaryFile(mode="w", suffix=".html", delete=False) as f:
            f.write(nan_styler.to_html())
            nan_html_path = f.name

        # Generate QA materials (plots and videos) for each recording
        qa_data = []
        for row in keypoint_videofile_metadata:
            video_id = int(row["video_id"])
            pose_estimation_path = row["pose_estimation_path"]
            pose_estimation_name = Path(pose_estimation_path).stem

            # Construct the expected plot path (already generated by outlier_removal)
            qa_dir = (
                kpms_project_output_dir / "QA" / "plots" / "keypoint_distance_outliers"
            )
            outlier_plot_path = qa_dir / f"{pose_estimation_name}.png"

            # Create overlay video output path: project_dir/QA/videos/overlay_keypoints/
            overlay_video_dir = (
                kpms_project_output_dir / "QA" / "videos" / "overlay_keypoints"
            )
            overlay_video_dir.mkdir(parents=True, exist_ok=True)
            overlay_video_path = (
                overlay_video_dir / f"{pose_estimation_name}_overlay.mp4"
            )

            # Get the full path to the video file
            video_file_path = find_full_path(
                get_kpms_root_data_dir(), row["video_path"]
            )

            # Generate overlay video for this specific recording (skip if already exists)
            if not overlay_video_path.exists():
                # Calculate frames for 1 minute of video
                frame_rate = fps_lookup.get(
                    video_id, 30.0
                )  # TODO: Default to 30fps if not found
                frames_for_dur = int(frame_rate * 6)

                logger.info(
                    f"Processing video {video_id}: {frame_rate}fps -> {frames_for_dur} frames for 1min"
                )

                overlay_keypoints_on_video(
                    video_path=video_file_path.as_posix(),
                    coordinates=coordinates[
                        pose_estimation_name
                    ],  # Pass coordinates for this specific recording
                    skeleton=kpms_dj_config_dict["skeleton"],
                    bodyparts=list(use_bodyparts),
                    output_path=overlay_video_path.as_posix(),
                    frames=range(frames_for_dur),
                )
                logger.info(f"Generated overlay video: {overlay_video_path}")
            else:
                logger.info(
                    f"Overlay video already exists, skipping: {overlay_video_path}"
                )

            qa_data.append(
                {
                    "video_id": video_id,
                    "outlier_plot_path": outlier_plot_path,
                    "overlay_video_path": overlay_video_path,
                }
            )

        completion_time = datetime.now(timezone.utc)
        duration_seconds = (completion_time - execution_time).total_seconds()

        return (
            nan_html_path,
            qa_data,
            duration_seconds,
        )

    def make_insert(
        self,
        key,
        nan_html_path,
        qa_data,
        duration_seconds,
    ):
        """
        Insert QA data into the PreProcessingQA table and part tables.
        """
        # Insert in the main table
        self.insert1(
            {
                **key,
                "nan_breakdown": nan_html_path,
                "qa_duration": duration_seconds,
            }
        )

        # Insert QA materials (plots and videos)
        if qa_data:
            self.VideoQA.insert(
                [
                    {
                        **key,
                        "video_id": data["video_id"],
                        "outlier_plot": data["outlier_plot_path"],
                        "overlay_video": data["overlay_video_path"],
                    }
                    for data in qa_data
                ]
            )


@schema
class PCAFit(dj.Computed):
    """Fit Principal Component Analysis (PCA) model for dimensionality reduction of keypoint data.

    Attributes:
        PreProcessing (foreign key)     : `PreProcessing` Key.
        pca_fit_time (datetime)         : datetime of the PCA fitting analysis.
        pca_fit_duration (int)          : Execution time of the PCA fitting analysis in seconds.
    """

    definition = """
    -> PreProcessing                      # `PreProcessing` Key
    ---
    pca_fit_time=NULL        : datetime  # datetime of the PCA fitting analysis
    pca_fit_duration=NULL    : int       # Execution time of the PCA fitting analysis in seconds.
    """

    class File(dj.Part):
        """
        Store the PCA files (pca.p, data.pkl, metadata.pkl files).
        """

        definition = """
        -> master
        file_name    : varchar(255)    # name of the file (e.g. 'pca.p', 'data.pkl', 'metadata.pkl').
        ---
        file_path    : filepath@moseq-train-processed   # path to the file (relative to the project output directory).
        """

    def make(self, key):
        """
        Format keypoint data and fit PCA model for dimensionality reduction.

        Args:
            key (dict): `PreProcessing` Key

        High-Level Logic:
        1. Fetch project output directory and load configuration.
        2. Format keypoint data with coordinates and confidences.
        3. Fit PCA model and save as `pca.p` file.
        4. Insert creation datetime into table.
        """
        import jax
        from keypoint_moseq import fit_pca, format_data, load_pca, save_pca

        jax.config.update("jax_enable_x64", True)

        kpms_project_output_dir, task_mode = (PCATask & key).fetch1(
            "kpms_project_output_dir", "task_mode"
        )
        kpms_project_output_dir = (
            Path(get_kpms_processed_data_dir()) / kpms_project_output_dir
        )
        use_bodyparts = (BodyParts & key).fetch1("use_bodyparts")
        coordinates, confidences = (PreProcessing & key).fetch1(
            "coordinates", "confidences"
        )

        # Load config file
        kpms_dj_config_path = (PreProcessing.ConfigFile & key).fetch1("config_file")
        kpms_dj_config_dict = kpms_reader.load_kpms_dj_config(
            config_path=kpms_dj_config_path,
            build_indexes=True,
        )

        execution_time = datetime.now(timezone.utc)

        # Format keypoint data
        data, metadata = format_data(
            coordinates=coordinates,
            confidences=confidences,
            use_bodyparts=use_bodyparts,
        )

        # Save data and metadata to pickle files
        data_path = kpms_project_output_dir / "data.pkl"
        metadata_path = kpms_project_output_dir / "metadata.pkl"
        with open(data_path, "wb") as f:
            pickle.dump(data, f)
        with open(metadata_path, "wb") as f:
            pickle.dump(metadata, f)

        # Fit PCA model and save as `pca.p` file
        if task_mode == "trigger":
            pca = fit_pca(**data, **kpms_dj_config_dict)
            save_pca(pca, kpms_project_output_dir.as_posix())

        # Check if pca file exists
        pca_path = kpms_project_output_dir / "pca.p"
        if not pca_path.exists():
            raise FileNotFoundError(
                f"No pca file (`pca.p`) found in the project directory {kpms_project_output_dir}"
            )
        file_paths = [pca_path, data_path, metadata_path]

        completion_time = datetime.now(timezone.utc)
        duration_seconds = (
            (completion_time - execution_time).total_seconds()
            if task_mode == "trigger"
            else None
        )

        self.insert1(
            {
                **key,
                "pca_fit_time": execution_time,
                "pca_fit_duration": duration_seconds,
            }
        )

        self.File.insert(
            [
                {
                    **key,
                    "file_name": file_path.name,
                    "file_path": file_path,
                }
                for file_path in file_paths
            ]
        )


@schema
class LatentDimension(dj.Computed):
    """
    Determine the optimal latent dimension for model fitting based on variance explained by PCA components.

    Attributes:
        PCAFit (foreign key)               : `PCAFit` Key.
        variance_percentage (float)        : Variance threshold. Fixed value to 90%.
        latent_dimension (int)             : Number of principal components required to explain the specified variance.
        latent_dim_desc (varchar)          : Automated description of the computation result.
    """

    definition = """
    -> PCAFit                                   # `PCAFit` Key
    ---
    variance_percentage      : float            # Variance threshold. Fixed value to 90 percent.
    latent_dimension         : int              # Number of principal components required to explain the specified variance.
    latent_dim_desc=''       : varchar(1000)    # Automated description of the computation result.
    """

    class Plots(dj.Part):
        """
        Store the PCA visualization plots.
        """

        definition = """
        -> master
        ---
        scree_plot  : attach    # A cumulative scree plot showing explained variance
        pcs_plot    : attach    # A visualization of each Principal Component (PC)
        pcs_xy_plot : attach    # A visualization of the Principal Components (PCs) in the XY plane
        """

    def make(self, key):
        """
        Compute and store the optimal latent dimension based on 90% variance threshold.

        Args:
            key (dict): `PCAFit` Key.

        Raises:
            FileNotFoundError: No PCA model found in project directory.

        High-Level Logic:
        1. Fetch project output directory and load PCA model.
        2. Calculate cumulative explained variance ratio.
        3. Determine number of components needed for 90% variance.
        4. Insert results into table.
        """
        import tempfile

        from keypoint_moseq import load_pca

        VARIANCE_THRESHOLD = 0.90

        kpms_project_output_dir = (PCATask & key).fetch1("kpms_project_output_dir")
        kpms_project_output_dir = (
            Path(get_kpms_processed_data_dir()) / kpms_project_output_dir
        )

        # Fetch PCA file path from upstream PCAFit.File table
        pca_path = (PCAFit.File & key & 'file_name="pca.p"').fetch1("file_path")
        pca = load_pca(Path(pca_path).parent.as_posix())
        cs = np.cumsum(
            pca.explained_variance_ratio_
        )  # explained_variance_ratio_ndarray of shape (n_components,)

        if cs[-1] < VARIANCE_THRESHOLD:
            latent_dimension = len(cs)
            variance_percentage = cs[-1] * 100
            latent_dim_desc = (
                f"All components together only explain {cs[-1]*100}% of variance."
            )
        else:
            latent_dimension = (cs > VARIANCE_THRESHOLD).nonzero()[0].min() + 1
            variance_percentage = VARIANCE_THRESHOLD * 100
            latent_dim_desc = f">={VARIANCE_THRESHOLD*100}% of variance explained by {(cs>VARIANCE_THRESHOLD).nonzero()[0].min()+1} components."

        # Load config file
        kpms_dj_config_path = (PreProcessing.ConfigFile & key).fetch1("config_file")
        kpms_dj_config_dict = kpms_reader.load_kpms_dj_config(
            config_path=kpms_dj_config_path, build_indexes=False
        )

        # Generate scree plot
        scree_fig = plt.figure()
        num_pcs = len(pca.components_)
        plt.plot(np.arange(num_pcs) + 1, np.cumsum(pca.explained_variance_ratio_))
        plt.xlabel("PCs")
        plt.ylabel("Explained variance")
        plt.gcf().set_size_inches((2.5, 2))
        plt.grid()
        plt.tight_layout()

        # Generate PCs plot
        pcs_fig = viz_utils.plot_pcs(
            pca,
            interactive=False,
            project_dir=kpms_project_output_dir,
            **kpms_dj_config_dict,
        )

        # Load the pcs-xy.pdf file
        pcs_xy_file = kpms_project_output_dir / "pcs-xy.pdf"

        if not pcs_xy_file.exists():
            raise FileNotFoundError(
                f"No pcs xy file (`pcs-xy.pdf`) found in the project directory {kpms_project_output_dir}"
            )

        # Save plots
        tmpdir = tempfile.TemporaryDirectory()
        fname = f"{key['kpset_id']}_{key['bodyparts_id']}"
        scree_path = Path(tmpdir.name) / f"{fname}_scree_plot.png"
        scree_fig.savefig(scree_path)
        pcs_path = Path(tmpdir.name) / f"{fname}_pcs_plot.png"
        pcs_fig.savefig(pcs_path)

        # Insert main results
        self.insert1(
            dict(
                **key,
                variance_percentage=variance_percentage,
                latent_dimension=latent_dimension,
                latent_dim_desc=latent_dim_desc,
            )
        )

        # Insert plots
        self.Plots.insert1(
            {
                **key,
                "scree_plot": scree_path,
                "pcs_plot": pcs_path,
                "pcs_xy_plot": pcs_xy_file,
            }
        )

        tmpdir.cleanup()


@schema
class PreFitTask(dj.Manual):
    """Define parameters for Stage 1: Auto-Regressive Hidden Markov Model (AR-HMM) pre-fitting.

    Attributes:
        PCAFit (foreign key)                : `PCAFit` task.
        pre_latent_dim (int)                : Latent dimension to use for the model pre-fitting.
        pre_kappa (int)                     : Kappa value to use for the model pre-fitting (controls syllable duration).
        pre_num_iterations (int)            : Number of Gibbs sampling iterations to run in the model pre-fitting (typically 10-50).
        model_name (varchar)                : Name of the model to be loaded if `task_mode='load'`
        task_mode (enum)                    : 'load': load computed analysis results, 'trigger': trigger computation
        pre_fit_desc(varchar)               : User-defined description of the pre-fitting task.
    """

    definition = """
    -> PCAFit                                            # `PCAFit` Key
    pre_latent_dim               : int                   # Latent dimension to use for the model pre-fitting.
    pre_kappa                    : int                   # Kappa value to use for the model pre-fitting (controls syllable duration).
    pre_num_iterations           : int                   # Number of Gibbs sampling iterations to run in the model pre-fitting (typically 10-50).
    ---
    model_name=''                : varchar(1000)         # Optional. Name of the model to be loaded if `task_mode='load'`
    task_mode='load'             :enum('trigger','load') # 'load': load computed analysis results, 'trigger': trigger computation
    pre_fit_desc=''              : varchar(1000)         # Optional.User-defined description of the pre-fitting task
    """


@schema
class PreFit(dj.Computed):
    """Fit Auto-Regressive Hidden Markov Model (AR-HMM) for initial behavioral syllable discovery.

    Attributes:
        PreFitTask (foreign key)                : `PreFitTask` Key.
        model_name (varchar)                    : Name of the model as "model_name".
        pre_fit_duration (float)                : Time duration (seconds) of the model fitting computation.
    """

    definition = """
    -> PreFitTask                                # `PreFitTask` Key
    ---
    model_name=''                : varchar(1000) # Name of the model as "kpms_project_output_dir/model_name"
    pre_fit_time=NULL            : datetime      # datetime of the model fitting computation.
    pre_fit_duration=NULL        : float         # Time duration (seconds) of the model fitting computation
    """

    class ConfigFile(dj.Part):
        """
        Store the updated configuration file after PreFit computation.
        """

        definition = """
        -> master
        ---
        config_file: attach  # Updated KPMS DJ config file after PreFit computation.
        """

    class File(dj.Part):
        """
        Store the checkpoint file and model data file used for resuming the pre-fitting process.
        """

        definition = """
        -> master
        file_name    : varchar(255)                  # Name of the output file (e.g. 'checkpoint.h5', 'model_data.pkl').
        ---
        file_path    : filepath@moseq-train-processed # Path to the file in the processed data directory.
        """

    class Plots(dj.Part):
        """
        Store the fitting progress of the PreFit computation.
        """

        definition = """
        -> master
        ---
        fitting_progress_plot_png: attach
        fitting_progress_plot_pdf: attach
        """

    def make(self, key):
        """
        Fit AR-HMM model for initial behavioral syllable discovery.

        Args:
            key (dict): Dictionary with the `PreFitTask` Key.

        Raises:
            FileNotFoundError: No PCA model found in project directory.

        High-Level Logic:
        1. Fetch project output directory and model parameters.
        2. Update configuration with latent dimension and kappa values.
        3. Load PCA model and format keypoint data.
        4. Initialize and fit AR-HMM model.
        5. Calculate fitting duration and insert results.
        """
        from keypoint_moseq import (
            fit_model,
            format_data,
            init_model,
            load_pca,
            update_hypparams,
        )

        kpms_project_output_dir = find_full_path(
            get_kpms_processed_data_dir(),
            (PCATask & key).fetch1("kpms_project_output_dir"),
        )
        pre_latent_dim, pre_kappa, pre_num_iterations, task_mode, model_name = (
            PreFitTask & key
        ).fetch1(
            "pre_latent_dim",
            "pre_kappa",
            "pre_num_iterations",
            "task_mode",
            "model_name",
        )

        if task_mode == "trigger":
            # Configure JAX precision
            import jax

            jax.config.update("jax_enable_x64", True)
            from keypoint_moseq import estimate_sigmasq_loc

            kpms_dj_config_abs_path = (PreProcessing.ConfigFile & key).fetch1(
                "config_file"
            )
            pca_path = (PCAFit.File & key & 'file_name="pca.p"').fetch1("file_path")
            pca = load_pca(Path(pca_path).parent.as_posix())
            coordinates, confidences = (PreProcessing & key).fetch1(
                "coordinates", "confidences"
            )
            data_path = (PCAFit.File & key & 'file_name="data.pkl"').fetch1("file_path")
            metadata_path = (PCAFit.File & key & 'file_name="metadata.pkl"').fetch1(
                "file_path"
            )
            data = pickle.load(open(data_path, "rb"))
            metadata = pickle.load(open(metadata_path, "rb"))
            average_frame_rate = (PreProcessing & key).fetch1("average_frame_rate")

            # Update kpms_dj_config file in disk with new latent_dim and kappa values
            kpms_dj_config_dict_for_save = kpms_reader.load_kpms_dj_config(
                config_path=kpms_dj_config_abs_path, build_indexes=False
            )
            # Update and save config to disk
            kpms_dj_config_dict_for_save = kpms_reader.update_kpms_dj_config(
                config_dict=kpms_dj_config_dict_for_save,
                config_path=kpms_dj_config_abs_path,
                latent_dim=int(pre_latent_dim),
                kappa=float(pre_kappa),
                sigmasq_loc=float(
                    estimate_sigmasq_loc(
                        data["Y"], data["mask"], filter_size=average_frame_rate
                    )
                ),
            )
            # Load config with indexes for model initialization
            kpms_dj_config_dict = kpms_reader.load_kpms_dj_config(
                config_path=kpms_dj_config_abs_path, build_indexes=True
            )

            # Initialize the model
            model = init_model(
                data=data, metadata=metadata, pca=pca, **kpms_dj_config_dict
            )
            # Update the model hyperparameters
            model = update_hypparams(
                model,
                kappa=float(pre_kappa.item()),
                latent_dim=int(pre_latent_dim.item()),
            )
            # Determine model directory name for outputs
            if model_name is None or not str(model_name).strip():
                model_name = f"latent_dim_{pre_latent_dim.item()}_kappa_{pre_kappa.item()}_iters_{pre_num_iterations.item()}"
            else:
                model_name = str(model_name)

            execution_time = datetime.now(timezone.utc)
            # Fit the model
            model, _ = fit_model(
                model=model,
                model_name=model_name,
                data=data,
                metadata=metadata,
                project_dir=kpms_project_output_dir.as_posix(),
                ar_only=True,
                num_iters=pre_num_iterations,
                generate_progress_plots=True,  # saved to {project_dir}/{model_name}/plots/
                save_every_n_iters=10,
            )
            # Create a PNG version fo the PDF progress plot
            png_path, pdf_path = viz_utils.copy_pdf_to_png(
                kpms_project_output_dir, model_name
            )
            # Define model_name_full_path for checkpoint file search
            model_name_full_path = find_full_path(kpms_project_output_dir, model_name)

        else:
            # Load mode must specify a model_name
            if model_name is None or not str(model_name).strip():
                raise ValueError("model_name is required when task_mode='load'")
            model_name_full_path = find_full_path(kpms_project_output_dir, model_name)
            pdf_path = model_name_full_path / "fitting_progress.pdf"
            png_path = model_name_full_path / "fitting_progress.png"

        # Get the path to the updated config file
        kpms_dj_config_path = kpms_reader._kpms_dj_config_path(kpms_project_output_dir)

        if not pdf_path.exists():
            raise FileNotFoundError(f"PreFit PDF progress plot not found at {pdf_path}")
        if not png_path.exists():
            raise FileNotFoundError(f"PreFit PNG progress plot not found at {png_path}")

        # Find checkpoint file
        checkpoint_files = []
        for pattern in ("checkpoint*", "*.h5"):
            checkpoint_files.extend(model_name_full_path.glob(pattern))
        if checkpoint_files:
            checkpoint_file = max(checkpoint_files, key=lambda f: f.stat().st_mtime)
        else:
            raise FileNotFoundError(
                f"No checkpoint files found in {model_name_full_path}"
            )

        completion_time = datetime.now(timezone.utc)

        if task_mode == "trigger":
            duration_seconds = (completion_time - execution_time).total_seconds()
        else:
            duration_seconds = None

        # Save model dictionary as pickle file
        model_data_filename = "model_data.pkl"
        model_data_file = model_name_full_path / model_data_filename
        with open(model_data_file, "wb") as f:
            pickle.dump(model, f)

        file_paths = [checkpoint_file, model_data_file]

        self.insert1(
            {
                **key,
                "model_name": model_name,
                "pre_fit_duration": duration_seconds,
            }
        )

        self.File.insert(
            [
                {
                    **key,
                    "file_name": file.name,
                    "file_path": file.as_posix(),
                }
                for file in file_paths
            ]
        )

        self.ConfigFile.insert1(
            dict(
                **key,
                config_file=kpms_dj_config_path,
            )
        )

        self.Plots.insert1(
            {
                **key,
                "fitting_progress_plot_png": png_path,
                "fitting_progress_plot_pdf": pdf_path,
            }
        )


@schema
class FullFitTask(dj.Manual):
    """Define parameters for FullFit step of model fitting.

    Attributes:
        PCAFit (foreign key)                 : `PCAFit` Key.
        full_latent_dim (int)                : Latent dimension to use for the model full fitting.
        full_kappa (int)                     : Kappa value to use for the model full fitting (typically lower than pre-fit kappa).
        full_num_iterations (int)            : Number of Gibbs sampling iterations to run in the model full fitting (typically 200-500).
        model_name (varchar)                 : Name of the model to be loaded if `task_mode='load'`
        task_mode (enum)                     : 'load': load computed analysis results, 'trigger': trigger computation
        full_fit_desc(varchar)               : User-defined description of the model full fitting task.
    """

    definition = """
    -> PCAFit                                           # `PCAFit` Key
    full_latent_dim              : int                  # Latent dimension to use for the model full fitting
    full_kappa                   : int                  # Kappa value to use for the model full fitting (typically lower than pre-fit kappa).
    full_num_iterations          : int                  # Number of Gibbs sampling iterations to run in the model full fitting (typically 200-500).
    ---
    model_name=''                : varchar(1000)        # Optional. Name of the model to be loaded if `task_mode='load'`
    task_mode='load'             :enum('load','trigger')# Trigger or load the task
    full_fit_desc=''             : varchar(1000)        # Optional.User-defined description of the model full fitting task
    """


@schema
class FullFit(dj.Computed):
    """Fit the complete Keypoint Switching Linear Dynamical System (Keypoint-SLDS) model.

    Attributes:
        FullFitTask (foreign key)            : `FullFitTask` Key.
        model_name                           : varchar(100) # Name of the model as "kpms_project_output_dir/model_name"
        full_fit_duration (float)            : Time duration (seconds) of the full fitting computation
    """

    definition = """
    -> FullFitTask                                # `FullFitTask` Key
    ---
    model_name=''                 : varchar(100)  # Name of the model as "kpms_project_output_dir/model_name".
    full_fit_time=NULL            : datetime      # datetime of the full fitting computation.
    full_fit_duration=NULL        : float         # Time duration (seconds) of the full fitting computation.
    """

    class ConfigFile(dj.Part):
        """
        Store the updated configuration file after FullFit computation.
        """

        definition = """
        -> master
        ---
        config_file: attach  # Updated KPMS DJ config attachment.
        """

    class File(dj.Part):
        """
        Store the checkpoint file and model data file used for resuming the full-fitting process.
        """

        definition = """
        -> master
        file_name    : varchar(255)                  # Name of the output file (e.g. 'checkpoint.h5', 'model_data.pkl').
        ---
        file_path    : filepath@moseq-train-processed # Path to the file in the processed data directory.
        """

    class Plots(dj.Part):
        """
        Store the fitting progress of the FullFit computation.
        """

        definition = """
        -> master
        ---
        fitting_progress_plot_png: attach
        fitting_progress_plot_pdf: attach
        """

    def make(self, key):
        """
        Fit the complete Keypoint-SLDS model with spatial and temporal dynamics.

        Args:
            key (dict): Dictionary with the `FullFitTask` Key.

        Raises:
            FileNotFoundError: No PCA model found in project directory.

        High-Level Logic:
        1. Fetch project output directory and model parameters.
        2. Update configuration with latent dimension and kappa values.
        3. Load PCA model and format keypoint data.
        4. Initialize and fit Keypoint-SLDS model.
        5. Reindex syllable labels by frequency.
        6. Calculate fitting duration and insert results.
        """
        import jax

        jax.config.update("jax_enable_x64", True)

        from keypoint_moseq import (
            estimate_sigmasq_loc,
            fit_model,
            format_data,
            init_model,
            load_pca,
            reindex_syllables_in_checkpoint,
            update_hypparams,
        )

        kpms_project_output_dir = find_full_path(
            get_kpms_processed_data_dir(),
            (PCATask & key).fetch1("kpms_project_output_dir"),
        )
        full_latent_dim, full_kappa, full_num_iterations, task_mode, model_name = (
            FullFitTask & key
        ).fetch1(
            "full_latent_dim",
            "full_kappa",
            "full_num_iterations",
            "task_mode",
            "model_name",
        )

        if task_mode == "trigger":
            import pickle

            from keypoint_moseq import load_checkpoint

            pca_path = (PCAFit.File & key & 'file_name="pca.p"').fetch1("file_path")
            pca = load_pca(Path(pca_path).parent.as_posix())
            coordinates, confidences = (PreProcessing & key).fetch1(
                "coordinates", "confidences"
            )
            data_path = (PCAFit.File & key & 'file_name="data.pkl"').fetch1("file_path")
            metadata_path = (PCAFit.File & key & 'file_name="metadata.pkl"').fetch1(
                "file_path"
            )
            data = pickle.load(open(data_path, "rb"))
            metadata = pickle.load(open(metadata_path, "rb"))
            average_frame_rate = (PreProcessing & key).fetch1("average_frame_rate")

            kpms_dj_config_abs_path = (PreProcessing.ConfigFile & key).fetch1(
                "config_file"
            )

            kpms_dj_config_dict_for_save = kpms_reader.load_kpms_dj_config(
                config_path=kpms_dj_config_abs_path, build_indexes=False
            )
            sigmasq_loc_val = float(
                estimate_sigmasq_loc(
                    data["Y"], data["mask"], filter_size=average_frame_rate
                )
            )
            kpms_dj_config_dict_for_save = kpms_reader.update_kpms_dj_config(
                config_dict=kpms_dj_config_dict_for_save,
                config_path=kpms_dj_config_abs_path,
                latent_dim=int(full_latent_dim),
                kappa=float(full_kappa),
                sigmasq_loc=sigmasq_loc_val,
            )

            kpms_dj_config_dict = kpms_reader.load_kpms_dj_config(
                config_path=kpms_dj_config_abs_path, build_indexes=True
            )

            # Determine model directory name for outputs
            if model_name is None or not str(model_name).strip():
                model_name = f"latent_dim_{full_latent_dim.item()}_kappa_{full_kappa.item()}_iters_{full_num_iterations.item()}"
            else:
                model_name = str(model_name)

            # Try to load pre-fit model for the same latent_dim and kappa values
            pre_model = None
            # More optimal: check existence before fetching to avoid try/except
            pre_model_key_query = (
                PreFitTask
                & {"kpset_id": key["kpset_id"], "bodyparts_id": key["bodyparts_id"]}
                & {
                    "pre_kappa": key["full_kappa"],
                    "pre_latent_dim": key["full_latent_dim"],
                }
            )
            if pre_model_key_query:
                pre_model_key = pre_model_key_query.fetch1("KEY")
                pre_model_file = (
                    PreFit.File & pre_model_key & 'file_name="checkpoint.h5"'
                ).fetch1("file_path")
                with open(pre_model_file, "rb") as f:
                    pre_model = pickle.load(f)
                logger.info(
                    f"Using PreFit model {pre_model_key_query} as warm start for FullFit"
                )

            execution_time = datetime.now(timezone.utc)

            # Initialize model: Use PreFit if available, otherwise initialize fresh
            try:
                if pre_model is not None:
                    model_to_fit = pre_model
                else:
                    # Only initialize fresh model if no PreFit available
                    model_to_fit = init_model(
                        data=data, metadata=metadata, pca=pca, **kpms_dj_config_dict
                    )
                    # Update the model hyperparameters
                    model_to_fit = update_hypparams(
                        model_to_fit,
                        kappa=float(full_kappa.item()),
                        latent_dim=int(full_latent_dim.item()),
                    )
            except Exception as e:
                raise ValueError(f"Model initialization failed: {e}")

            # Fit the model
            try:

                model, model_name = fit_model(
                    model=model_to_fit,
                    model_name=model_name,
                    data=data,
                    metadata=metadata,
                    project_dir=kpms_project_output_dir.as_posix(),
                    ar_only=False,
                    num_iters=full_num_iterations,
                    generate_progress_plots=True,
                    save_every_n_iters=1,  # TODO: to change to a higher value
                    verbose=False,
                )  # checkpoint will be saved at project_dir/model_name
            except Exception as e:
                raise ValueError(f"FullFit training failed: {e}")

            try:
                # Reindex the syllables in the checkpoint file
                reindex_syllables_in_checkpoint(
                    project_dir=kpms_project_output_dir.as_posix(),
                    model_name=model_name,
                )
            except Exception as e:
                raise ValueError(
                    f"Reindexing syllables failed due to FullFit training failure: {e}"
                )

            # Create a PNG version fo the PDF progress plot
            model_name_full_path = find_full_path(kpms_project_output_dir, model_name)
            pdf_path = model_name_full_path / "fitting_progress.pdf"
            png_path = model_name_full_path / "fitting_progress.png"

            if pdf_path.exists():
                png_path, pdf_path = viz_utils.copy_pdf_to_png(
                    kpms_project_output_dir, model_name
                )
            else:
                logger.warning(f"No progress PDF found at {pdf_path}")
        else:
            # Load mode must specify a model_name
            if model_name is None or not str(model_name).strip():
                raise ValueError("`model_name` is required when task_mode='load'")

            model_name_full_path = find_full_path(kpms_project_output_dir, model_name)
            pdf_path = model_name_full_path / "fitting_progress.pdf"
            png_path = model_name_full_path / "fitting_progress.png"

        # Get the path to the updated config file
        kpms_dj_config_abs_path = kpms_reader._kpms_dj_config_path(
            kpms_project_output_dir
        )
        if not pdf_path.exists():
            raise FileNotFoundError(f"PreFit PDF progress plot not found at {pdf_path}")
        if not png_path.exists():
            raise FileNotFoundError(f"PreFit PNG progress plot not found at {png_path}")

        # Find checkpoint file
        checkpoint_files = []
        for pattern in ("checkpoint*", "*.h5"):
            checkpoint_files.extend(model_name_full_path.glob(pattern))
        if checkpoint_files:
            checkpoint_file = max(checkpoint_files, key=lambda f: f.stat().st_mtime)
        else:
            raise FileNotFoundError(
                f"No checkpoint files found in {model_name_full_path}"
            )

        # Save model dictionary as pickle file in the model directory
        model_data_filename = "model_data.pkl"
        model_data_file = model_name_full_path / model_data_filename
        with open(model_data_file, "wb") as f:
            pickle.dump(model, f)

        file_paths = [checkpoint_file, model_data_file]

        completion_time = datetime.now(timezone.utc)
        duration_seconds = (
            (completion_time - execution_time).total_seconds()
            if task_mode == "trigger"
            else None
        )

        self.insert1(
            {
                **key,
                "model_name": (
                    kpms_project_output_dir.relative_to(get_kpms_processed_data_dir())
                    / Path(model_name).name
                ).as_posix(),
                "full_fit_time": completion_time,
                "full_fit_duration": duration_seconds,
            }
        )

        self.File.insert(
            [
                {
                    **key,
                    "file_name": file.name,
                    "file_path": file.as_posix(),
                }
                for file in file_paths
            ]
        )

        self.ConfigFile.insert1(
            {
                **key,
                "config_file": kpms_dj_config_abs_path,
            }
        )

        self.Plots.insert1(
            {
                **key,
                "fitting_progress_plot_png": png_path,
                "fitting_progress_plot_pdf": pdf_path,
            }
        )


@schema
class ModelScore(dj.Computed):
    """Compute model scores for trained models.

    Computes Marginal Log Likelihood (MLL) for a single model.
    """

    definition = """
    -> FullFit
    ---
    score=NULL          : float           # Model score (MLL for single model)
    """

    def make(self, key):
        import jax.numpy as jnp
        from keypoint_moseq import load_checkpoint
        from keypoint_moseq.fitting import marginal_log_likelihood

        # Get checkpoint file for this specific model
        checkpoint_file = (
            FullFit.File & key & 'file_name LIKE "%checkpoint.h5"'
        ).fetch1("file_path")

        # Load the checkpoint to get model data
        model, data, _, _ = load_checkpoint(path=checkpoint_file)

        # Compute marginal log likelihood for single model
        mask = jnp.array(data["mask"])
        x = jnp.array(model["states"]["x"])
        Ab = jnp.array(model["params"]["Ab"])
        Q = jnp.array(model["params"]["Q"])
        pi = jnp.array(model["params"]["pi"])
        mll = marginal_log_likelihood(mask, x, Ab, Q, pi)
        score = float(mll)  # Store as "score" - this is MLL

        self.insert1(
            {
                **key,
                "score": score,
            }
        )


@schema
class SelectedFullFit(dj.Manual):
    """Register selected FullFit models for use in the inference pipeline.

    Attributes:
        FullFit (foreign key)          : `FullFit` Key.
        registered_model_name (varchar): User-friendly model name
        registered_model_desc (varchar): Optional user-defined description
    """

    definition = """
    -> FullFit
    ---
    registered_model_name         : varchar(1000)   # User-friendly model name
    registered_model_desc=''      : varchar(1000) # Optional user-defined description
    """

    @classmethod
    def select_best_model(cls, key, model_desc="Best model based on MLL score"):
        """Automatically select the best model for a FullFit based on highest MLL score.

        Args:
            pcafit_key (dict): PCAFit key to filter models
            model_desc (str): Description for the selected model

        Returns:
            dict: The key of the selected model
        """
        # Get all models with their scores for this specific PCAFit
        models_with_scores = (FullFit * ModelScore & key).fetch()

        if len(models_with_scores) == 0:
            raise ValueError(
                f"No models with scores found for PCAFit {key}. Run ModelScore.populate() first."
            )

        # Find the model with the highest score (best MLL)
        best_model_idx = models_with_scores["score"].argmax()
        best_model_key = {
            k: models_with_scores[k][best_model_idx] for k in FullFit.primary_key
        }
        best_model_name = models_with_scores["model_name"][best_model_idx]
        best_score = models_with_scores["score"][best_model_idx]

        print(f"Selected best model: {best_model_name}")
        print(f"Model score (MLL): {best_score:.2f}")

        # Insert the best model into SelectedFullFit
        cls.insert1(
            {
                **best_model_key,
                "registered_model_name": best_model_name,
                "registered_model_desc": f"{model_desc} (MLL: {best_score:.2f})",
            },
            skip_duplicates=True,
        )

        return best_model_key
